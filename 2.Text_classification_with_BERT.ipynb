{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUu8O6h9b3Xr"
   },
   "source": [
    "# Text classification with BERT\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from **Transformers**) is a NLP model developed by Google in 2018. It is a model that is already pre-trained on a 2,5000M (+- 170 GB) words corpus from Wikipedia. \n",
    "\n",
    "![bert](https://www.advisa.fr/wp-content/uploads/2019/10/google-bert-algorithm.jpg)\n",
    "\n",
    "To accomplish a particular NLP task, the pre-trained BERT model is used as a base and refined by adding an additional layer; the model can then be trained on a labeled data set dedicated to the NLP task to be performed. This is the very principle of **transfer learning**. It is important to note that BERT is a very large model with 12 layers, 12 attention heads and 110 million parameters (BERT base).\n",
    "\n",
    "The BERT model is able to do :\n",
    "\n",
    "* translation\n",
    "* text generation\n",
    "* classification\n",
    "* question-answering\n",
    "* syntax analysis (tagging, parsing) \n",
    "\n",
    "**Why BERT?**\n",
    "\n",
    "Just look at the different benchmarks to quickly realize that the first models in the list are all forks of BERT.\n",
    "\n",
    "https://gluebenchmark.com/leaderboard\n",
    "\n",
    "## Let's go !\n",
    "\n",
    "To use BERT you need to have either pytorch or tensorflow installed in your environment. It is also preferable to have access to a GPU on your computer. If you don't have a GPU use Google Colab. \n",
    "\n",
    "**Exercise :** Use tensorflow or pytorch to check if you have a GPU.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkXZryMeff9U"
   },
   "source": [
    "Next, let’s install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face. This package is an interface between BERT and pytorch and/or tensorflow.\n",
    "\n",
    "\n",
    "``!pip install transformers``\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0V7D5sqAoxxx"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "The dataset comes from Odile. She's a bot that tries to answer general questions on a few BeCode Discord servers. The sentences all come from conversations between learners and Odile on Discord.\n",
    "\n",
    "**Exercise :** Import ``'./dataset/odile_data.csv'`` file into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GvS1YNAnpHow"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "odile = pd.read_csv('./dataset/odile_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z8vLopCqR4B"
   },
   "source": [
    "## Analyze the dataset ! \n",
    "\n",
    "It's time to take a quick look at our data. \n",
    "\n",
    "**Exercise :** You must answer the following questions: \n",
    "* How many observations does the dataset contain?\n",
    "* How many different labels does the dataset contain?\n",
    "* Which labels contain the most observations?\n",
    "* Which labels contain the fewest observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oMm5EENcrZgk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1555\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "print(len(odile))\n",
    "print(len(odile.intent.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smalltalk_appraisal_good</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_confirmation_yes</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_user_likes_agent</th>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_confirmation_no</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_confirmation_cancel</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               sentence\n",
       "intent                                 \n",
       "smalltalk_appraisal_good             89\n",
       "smalltalk_confirmation_yes           82\n",
       "smalltalk_user_likes_agent           77\n",
       "smalltalk_confirmation_no            67\n",
       "smalltalk_confirmation_cancel        62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = odile.groupby('intent').count().sort_values(['sentence'], ascending = False)\n",
    "observations.head(5) #top 5 patients with most observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smalltalk_agent_sure</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_user_will_be_back</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_dialog_what_do_you_mean</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_understand_binary</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smalltalk_best_song</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   sentence\n",
       "intent                                     \n",
       "smalltalk_agent_sure                      5\n",
       "smalltalk_user_will_be_back               5\n",
       "smalltalk_dialog_what_do_you_mean         5\n",
       "smalltalk_understand_binary               4\n",
       "smalltalk_best_song                       3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7Vghgo-r9vd"
   },
   "source": [
    "## It's time to clean up !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OJYXmQFvv-4"
   },
   "source": [
    "Not all NLP tasks require the same preprocessing. In this case, we have to ask ourselves some questions: \n",
    "\n",
    "- Are there unwanted characters in the dataset? For example, do you want to keep the smiley's or not?  \n",
    "  - If, for example, you want to create labels to analyze feelings, it might be perishable to keep the smiley's.\n",
    "- Is it relevant to keep capital letters in sentences?\n",
    "  - In this case, capital letters don't really matter, because on one hand, not everyone starts their sentences with capital letters when chatting. On the other hand, the sentences are quite short, addressed directly to Odile. \n",
    "- Is it necessary to limit the number of characters in a sentence?\n",
    "  - Again in this case it may be preferable to limit the number of words. The questions asked to Odile are supposed to be short, as too long sentences could interfere with the classification if they contain too much information.\n",
    "\n",
    "There is no universal answer. Everything will depend on the expected result. \n",
    "\n",
    "**Exercise :** Clean the dataset.\n",
    "- Remove all unnecessary characters. You can choose to keep the smiley's or not.\n",
    "- Put all sentences in lower case.\n",
    "- Limit text to 256 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import contractions \n",
    "def clean_text(text):\n",
    "    # remove contractions first\n",
    "    text = contractions.fix(text)\n",
    "    # remove unwanted chars\n",
    "    text = re.sub(r'[^\\w]', ' ', text)\n",
    "    # remove starting and trailing spaces\n",
    "    text = text.lstrip()\n",
    "    text = text.rstrip()\n",
    "    # make everything lowercase\n",
    "    text = text.lower()\n",
    "    # delete multiple spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # limit to 256 words\n",
    "    wordlist = text.split()\n",
    "    words_text = len([item for item in wordlist])\n",
    "    if words_text < 256:\n",
    "        wordlist = [item[:] for item in wordlist]\n",
    "    else:\n",
    "        wordlist = [item[:256] for item in wordlist]\n",
    "    text = ' '.join([str(elem) for elem in wordlist]) \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "odile['sentence'] = odile['sentence'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who are you</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all about you</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is your personality</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>define yourself</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are you</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentence                        intent\n",
       "0               who are you  smalltalk_agent_acquaintance\n",
       "1             all about you  smalltalk_agent_acquaintance\n",
       "2  what is your personality  smalltalk_agent_acquaintance\n",
       "3           define yourself  smalltalk_agent_acquaintance\n",
       "4              what are you  smalltalk_agent_acquaintance"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmTXr0oyb-ab"
   },
   "source": [
    "## Label's encoding\n",
    "As you know, the machine needs to convert words into numbers so that it can interpret them. It's the same with labels. So we are going to create a dictionary that will allow us to convert all labels into numbers. \n",
    "\n",
    "**Exercise :** Create a dictionary that contains all the labels and assign an id to it. (Of course, there should be no duplicates). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_uniques = list(odile.intent.unique())\n",
    "label_dict = dict(enumerate(list_uniques))\n",
    "label_map = {v: k for k, v in label_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l85DWudEgFo6"
   },
   "source": [
    "**Exercise :** Create a column `id_label` in your dataframe and insert the id's of the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>intent</th>\n",
       "      <th>id_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who are you</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all about you</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is your personality</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>define yourself</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what are you</td>\n",
       "      <td>smalltalk_agent_acquaintance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sentence                        intent  id_label\n",
       "0               who are you  smalltalk_agent_acquaintance         0\n",
       "1             all about you  smalltalk_agent_acquaintance         0\n",
       "2  what is your personality  smalltalk_agent_acquaintance         0\n",
       "3           define yourself  smalltalk_agent_acquaintance         0\n",
       "4              what are you  smalltalk_agent_acquaintance         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odile['id_label'] = odile['intent'].map(label_map)\n",
    "odile.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHNUPFTIgmdK"
   },
   "source": [
    "When we make our predictions, the model will return the label id as a prediction. So it may be useful to save your label dictionary to be able to reinterpret the label for a human later on. \n",
    "\n",
    "**Exercise:** Save your label dictionary with pickle (or other). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "0JxFbYiLhLwa"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#exporting the intent encoder\n",
    "output = open('intent_encoder.pkl', 'wb')\n",
    "pickle.dump(label_map, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y9aJqnzbT0_"
   },
   "source": [
    "## Split your dataset !\n",
    "After all this time, I dare to hope that it is not necessary to explain this step anymore!\n",
    "\n",
    "**Exercise :** Create the variables X_train, X_test, y_train and y_test. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = odile.sentence\n",
    "y = odile.id_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fgk0IHRphk9v"
   },
   "source": [
    "## Tokenization \n",
    "If you don't know what tokenization is anymore look [here](../1.preprocessing/1.tokenization.ipynb)\n",
    "\n",
    "We will use the tokenizer provided by BERT. This is a pre-trained model that will save us time. \n",
    "\n",
    "**Exercise :** Create a ``tokenizer`` variable and instantiate ``BertTokenizer.from_pretrained()`` from ``transformers``. You have to load ``bert-base-uncased`` model. (Uncased for case-insensitive.) \n",
    "\n",
    "[Documentation](https://huggingface.co/transformers/main_classes/tokenizer.html#transformers.PreTrainedTokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6QDW3rLlb9Rr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFCaQWsNo4wC"
   },
   "source": [
    "Good! We have instantiated our tokenizer but we have not yet encoded our words in vector.\n",
    "To do this we will have to use the method ``tokenizer.batch_encode_plus()``. This method will convert our sentences into a vector and create the attention mask.\n",
    "\n",
    "\n",
    "\n",
    "**Exercise :** Create an ``encoded_data_train`` variable and instantiate `tokenizer.batch_encode_plus()`. First you have to specify the data. So pass the variable `X_train`.\n",
    "\n",
    "You need to know 4 parameters. \n",
    "\n",
    "- **padding :** this is the parameter to make all vectors have the same length. You can set it to True. We need it to work with the attention masks.\n",
    "\n",
    "- **return_attention_mask :** allows to have the vector of the attention mask in return. Set it to True. Without this mask, we cannot see the attention points of our model. \n",
    "- **max_length :** Maximum length of the sequence. You can set it to 256\n",
    " \n",
    "- **return_tensors :** Here depending on the framework you are using (Pytorch VS Tensorflow) you have to specify the type of tensors you want to return. \n",
    "\n",
    "  - For pytorch you have to specify \"pt\".\n",
    "  - For tensorflow you have to specify \"tf\".\n",
    "  - For a numpy array, you must indicate \"np\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t8e7hwPTtnv7"
   },
   "outputs": [],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(X_train, padding=True,\n",
    "                                                 return_attention_mask=True,\n",
    "                                                 max_length = 256, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1244, 23), dtype=int32, numpy=\n",
       "array([[ 101, 4931, 2054, ...,    0,    0,    0],\n",
       "       [ 101, 5754, 5313, ...,    0,    0,    0],\n",
       "       [ 101, 1045, 2064, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101, 1997, 2607, ...,    0,    0,    0],\n",
       "       [ 101, 2145, 3403, ...,    0,    0,    0],\n",
       "       [ 101, 2129, 2079, ...,    0,    0,    0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1244, 23), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1244, 23), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDY1oLUlrzKA"
   },
   "source": [
    "You must do the same for the test data set. \n",
    "\n",
    "**Exercise :** Create a `encoded_data_test` variable and do the same thing as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "aw5AITL8r3dA"
   },
   "outputs": [],
   "source": [
    "encoded_data_test = tokenizer.batch_encode_plus(X_test, padding=True,\n",
    "                                                 return_attention_mask=True,\n",
    "                                                 max_length = 256, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(311, 20), dtype=int32, numpy=\n",
       "array([[  101,  1045,  2066, ...,     0,     0,     0],\n",
       "       [  101,  2024,  2017, ...,     0,     0,     0],\n",
       "       [  101,  2057,  2024, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  2017,  2024, ...,     0,     0,     0],\n",
       "       [  101,  2515, 18750, ...,     0,     0,     0],\n",
       "       [  101,  2085,  9061, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(311, 20), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(311, 20), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Sd0LW_fy3Td"
   },
   "source": [
    "If you do `print(encoded_data_train)`, you will see we have a dictionary with the following keys: `'input_ids'`, `'token_type_ids'` and `'attention_mask'`.\n",
    "\n",
    "* **input_ids :** The sentence represented as a vector. The input_ids are the indices corresponding to each token in our sentence.\n",
    "\n",
    "* **attention_mask :** It points out which tokens the model should pay attention to and which ones it should not.\n",
    "\n",
    "* **token_type_ids :** Is used to bring together two sequences, we will not use it in this case.  \n",
    " But you can find more information by following this [link](https://huggingface.co/transformers/glossary.html#token-type-ids)\n",
    " \n",
    "\n",
    "**Exercise :** print ``encoded_data_train['input_ids']`` and ``encoded_data_train['attention_mask']``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Yc9liucPy33s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 101 4931 2054 ...    0    0    0]\n",
      " [ 101 5754 5313 ...    0    0    0]\n",
      " [ 101 1045 2064 ...    0    0    0]\n",
      " ...\n",
      " [ 101 1997 2607 ...    0    0    0]\n",
      " [ 101 2145 3403 ...    0    0    0]\n",
      " [ 101 2129 2079 ...    0    0    0]], shape=(1244, 23), dtype=int32) tf.Tensor(\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]], shape=(1244, 23), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data_train.input_ids, encoded_data_train.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1045  2066 ...     0     0     0]\n",
      " [  101  2024  2017 ...     0     0     0]\n",
      " [  101  2057  2024 ...     0     0     0]\n",
      " ...\n",
      " [  101  2017  2024 ...     0     0     0]\n",
      " [  101  2515 18750 ...     0     0     0]\n",
      " [  101  2085  9061 ...     0     0     0]], shape=(311, 20), dtype=int32) tf.Tensor(\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " ...\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 1 1 ... 0 0 0]], shape=(311, 20), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoded_data_test.input_ids, encoded_data_test.attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-5NK32bhpvp"
   },
   "source": [
    "## Preapare the dataset\n",
    "Whether it's for Pytorch or Tensorflow, we have to prepare the datasets (more simply said, convert the dataframes to tensors). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wHHlZZEGgYe"
   },
   "source": [
    "We need to convert `y_train`, `y_test` into a tensor. For pytorch you have to use ``torch.tensor()`` and for tensorflow ``tf.tensor()``.\n",
    "\n",
    "**Exercise :** Create a variable `labels_train` and create a tensor with `y_train`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OLZuudSQHquS"
   },
   "outputs": [],
   "source": [
    "labels_train = tf.convert_to_tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1244,), dtype=int64, numpy=array([56, 37, 61, ..., 38, 80, 52])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbBS9NyKHrgG"
   },
   "source": [
    "**Exercise :** Create a variable `labels_test` and create a tensor with `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "m2qgcWnDHu6E"
   },
   "outputs": [],
   "source": [
    "labels_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(311,), dtype=int64, numpy=\n",
       "array([70, 10, 20, 27, 75, 88,  4, 24, 32, 20,  2, 67, 38, 89, 32, 69, 20,\n",
       "       20, 87, 44, 42, 86, 45, 32,  9, 20, 13, 15, 15, 29, 37,  6, 45, 18,\n",
       "       31, 27, 88, 38, 83, 37,  4,  6, 37, 39, 32, 38, 14, 56, 20, 40, 37,\n",
       "       76, 10, 58, 70, 93, 37, 31, 64, 28, 25, 37,  1, 52, 54,  3, 75,  6,\n",
       "       52, 54, 27, 31, 43, 58, 79, 53, 15, 27, 12, 53, 37, 32, 35, 20, 13,\n",
       "       13,  3,  4, 74,  4, 45, 51, 38, 30, 40, 70,  6, 45, 35, 16, 27, 55,\n",
       "       37, 47, 20,  6, 13, 27, 12, 60, 10, 33, 51, 49, 51, 31,  4, 89,  2,\n",
       "       32, 27, 24, 32, 12, 52, 82, 30, 24, 27, 32, 48, 58, 38, 14, 47, 10,\n",
       "       70, 38, 37, 31, 42, 12, 32, 52, 32, 81, 34, 20, 16, 27, 24, 27, 70,\n",
       "       25, 69,  3, 27, 50, 42, 32, 51, 22,  6, 31, 10, 54, 16, 38, 19, 16,\n",
       "        4, 19, 76, 70, 19, 51, 29,  0, 89, 26, 25, 70, 67, 64, 75, 40, 31,\n",
       "       84, 31, 49, 31, 31, 20, 38, 42, 49, 27, 27, 70,  4,  4, 29, 33, 57,\n",
       "       20,  3, 62, 52, 40, 70,  6, 25, 31,  6, 32, 50, 34, 38, 64, 43, 52,\n",
       "       47, 92,  6, 16, 31, 70, 85, 56, 54, 27, 31, 16, 27, 32, 94, 45, 84,\n",
       "       24, 40, 18,  2, 32, 27, 24, 27, 52, 32, 37, 15, 42, 42, 13, 51, 70,\n",
       "       54,  9, 17, 51, 20, 61, 11, 27,  4, 40, 39, 52, 31, 16, 37, 45, 86,\n",
       "       12, 27, 70, 26, 20, 47, 71, 25, 25, 45, 38, 29, 16, 37, 68, 70, 73,\n",
       "       32, 27, 38, 31, 47, 16, 58, 38, 34, 13, 66, 70, 86, 27, 50, 12, 38,\n",
       "       93, 89,  4, 89, 47])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOffzBzJOHqd"
   },
   "source": [
    "Define the batch size.  \n",
    "\n",
    "**Exercise:** Create a `batch_size` variable. The number of samples will depend on several factors, such as the capacity of your graphics card. If your graphic card is not very powerful I advise you to put a small batch size of 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "c_rEZKlfO26u"
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-0JZYn3Hvth"
   },
   "source": [
    "Now we need to convert our encoded dataframe into a tensor.\n",
    "\n",
    "**Exercise :** Create the ``dataset_train`` and ``dataset_test`` variables and convert ``encoded_data_train`` and ``encoded_data_test`` into tensor.\n",
    "\n",
    "**PYTORCH  :** [Use torch.utils.data.Dataset class](https://classyvision.ai/tutorials/classy_dataset)  \n",
    "**Tensorflow :** [Use tf.data.Dataset.from_tensor_slices](https://medium.com/when-i-work-data/converting-a-pandas-dataframe-into-a-tensorflow-dataset-752f3783c168)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((encoded_data_train.input_ids, labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(23,), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = tf.data.Dataset.from_tensor_slices((encoded_data_test.input_ids, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(20,), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIsAt1OMIUbB"
   },
   "source": [
    "## Load BERT model\n",
    "Depending on what you use (pytorch or tensorflow) you will have to use the following class: \n",
    "\n",
    "pytorch = ``BertForSequenceClassification``  \n",
    "tensorflow = ``TFBertForSequenceClassification.from_pretrained()``\n",
    "\n",
    "⚠️ You must use the same model as the one used for tokenization. So in our case  ``bert-base-uncased``. \n",
    "\n",
    "\n",
    "[doc pytorch](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification)   \n",
    "[doc tensorflow](https://huggingface.co/transformers/model_doc/bert.html#tfbertforsequenceclassification)\n",
    "\n",
    "**Exercise:** Create a model variable and instantiate the `BertForSequenceClassification().from_pretrained()` (or `TFBertForSequenceClassification.from_pretrained()`). As a parameter, you must indicate the number of labels (normally 95).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "ND2HYBf7ZtPo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dropout_37', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0tdzs7FZtvH"
   },
   "source": [
    "**🔦 Pytorch only :** Assign the model to \"cuda\" device   \n",
    "``model.to(\"cuda\")``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Wn8dJaw-Ia6P"
   },
   "outputs": [],
   "source": [
    "# 🔦 PYTORCH user only !! \n",
    "# Assign the model to gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nG34SSC7lgLK"
   },
   "source": [
    "## Train your model\n",
    "\n",
    "It's time to start training the model!\n",
    "For this, the HuggingFace package simplifies our life by bringing us a ``Trainer()`` class.\n",
    "\n",
    "To use this class, we must first configure the model with the ``TrainingArguments()`` class. It is this class that will allow us to set the batch size, the number of epochs, ...\n",
    "\n",
    "⚠️ For tensorflow you have to use `TFTrainer()` and `TFTrainingArguments()` !!\n",
    "\n",
    "**Exercise :** import `Trainer` and `TrainingArgument` from transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_Mh_JPJ4GZDR"
   },
   "outputs": [],
   "source": [
    "from transformers import TFTrainer\n",
    "from transformers import TFTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET13n0Van391"
   },
   "source": [
    "**Exercise :** Create the ``training_args`` variable and instantiate the class `TrainingArguments`. You need to specify several parameters : \n",
    "* `output_dir` : Directory path for saving your template.\n",
    "* `num_train_epochs` : Number of epochs. Will depend on your machine, batch size, etc...\n",
    "* `per_device_train_batch_size` : batch size per GPU and for training. Here again the number will depend on your machine. If you have a weak GPU, I advise you to put 8 or 16.\n",
    "* `per_device_eval_batch_size` : batch size per GPU and for **testing**. During the evaluation, the gradient and backpropagation are not executed, so you can set a larger batch size.\n",
    "* `learnig_rate` : by default it is `5e-5`. But most likely you will have to change it.  Again, only your tests can define a good learning rate.\n",
    "* `logging_dir` : directory path for storing logs\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "I-vzsdAdGuao"
   },
   "outputs": [],
   "source": [
    "training_args = TFTrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-6,\n",
    "    logging_dir='./logs',            \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhEXD-iQvICE"
   },
   "source": [
    "We are going to improve the metrics,notably the f1 score.   \n",
    "[Copy and paste the compute_metrics found in this documentation.](https://huggingface.co/transformers/training.html#codecell14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "KV0AaYOVv4Nh"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLk76klvwAnS"
   },
   "source": [
    "**Exercise :** Create the ``trainer`` variable and instantiate the ``Trainer()`` or ``TFTrainer()`` class. You need to specify several parameters :\n",
    "* `model` : the `model` variable.\n",
    "* `args` : the `trainings_args` variable\n",
    "* `compute_metrics` : the `compute_metrics` function\n",
    "* `train_dataset` : the `train_dataset` variable\n",
    "* `test_dataset` : the `test_dataset` variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "O8h-eGH8KBDf"
   },
   "outputs": [],
   "source": [
    "trainer = TFTrainer(model=model, args=training_args, compute_metrics=compute_metrics,\n",
    "                    train_dataset= dataset_train, eval_dataset=dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA1G5MXyxUai"
   },
   "source": [
    "**Exercise :** Train your model with `trainer.train()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "MxfhLzeiPp41"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_training_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaj7zDmq0WlY"
   },
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuPbhEtIxv5T"
   },
   "source": [
    "**Exercise :** Evaluate your model with `trainer.evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "aAh0uSw1QGMP"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0meval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_tfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/transformers/trainer_tf.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataset, steps, num_examples, description, prediction_loss_only)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_prediction_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/envs/deep_learning/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvrH1DkeytPN"
   },
   "source": [
    "If you do not have an f1 score of at least 0.8, your model could be improved. If your score is very low or stagnant, change the learning rate values and adjust the batch size. You can also increase the number of epochs. Unfortunately, there is no magic parameter, it all depends on your environment. You will have to do some tests to find the right hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKeBmfxn0KTa"
   },
   "source": [
    "**Exercise :** Test your model by making a prediction on the phrase \"Hello how are you?\".\n",
    "You should get the label \"smalltalk_greetings_how_are_you\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Gam_xae0H2T"
   },
   "source": [
    "## Building the BERT model with Ktrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ktrain\n",
    "from ktrain import text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split dataset for bert\n",
    "(X_train_bert, y_train_bert), (X_test_bert, y_test_bert), preproc = txt.texts_from_df(odile, 'sentence',\n",
    "                                                                                        label_columns = 'id_label',\n",
    "                                                                                        lang = 'en',\n",
    "                                                                                        maxlen = 256,\n",
    "                                                                                        val_pct = 0.2,\n",
    "                                                                                        preprocess_mode='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 256\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = text.text_classifier('bert', (X_train_bert, y_train_bert), preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap model in ktrain learner object\n",
    "learner = ktrain.get_learner(model, train_data=(X_train_bert, y_train_bert),\n",
    "                             val_data=(X_test_bert, y_test_bert), batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find good learning rate\n",
    "# learner.lr_find() briefly simulate training to find good learning rate\n",
    "# learner.lr_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and stop at best epochs\n",
    "# learner.autofit(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting predictor variable\n",
    "# predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "# y_pred = predictor.predict(test_df['text'].tolist()//X_new)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 3e-05...\n",
      "Epoch 1/2\n",
      " 11/156 [=>............................] - ETA: 1:55:27 - loss: 4.7916 - accuracy: 0.0010    "
     ]
    }
   ],
   "source": [
    "# Train model with default learning rate (takes too long time to find good learning rate)\n",
    "learner.fit_onecycle(3e-5, 2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_Text_Classification_With_BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf.",
   "language": "python",
   "name": "tf."
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
